{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XAX7fYGihdp3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets,layers,models\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDm-N8qshkvc",
        "outputId": "808b8f6e-9843-4850-c582-280a70c48591"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "data_dir = pathlib.Path('/content/gdrive/MyDrive/data/data/images')\n",
        "file_paths = list(data_dir.rglob('*.*'))\n",
        "paths = [(path.parts[-2], str(path)) for path in file_paths]\n",
        "df = pd.DataFrame(data=paths, columns=['Class', 'Images'])\n",
        "df = df.sort_values('Class', ascending=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7LCRdrRhseC",
        "outputId": "06326b3a-8764-4bbe-f387-96fcad31e966"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Class                                             Images\n",
            "0  architecure  /content/gdrive/MyDrive/data/data/images/archi...\n",
            "1  architecure  /content/gdrive/MyDrive/data/data/images/archi...\n",
            "2  architecure  /content/gdrive/MyDrive/data/data/images/archi...\n",
            "3  architecure  /content/gdrive/MyDrive/data/data/images/archi...\n",
            "4  architecure  /content/gdrive/MyDrive/data/data/images/archi...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Count the number of images in each class')\n",
        "print(df['Class'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqFXl75zhvmq",
        "outputId": "f9649790-3013-4fd1-ed2d-552517f0da38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count the number of images in each class\n",
            "travel and  adventure    8810\n",
            "food and d rinks         8780\n",
            "architecure              8763\n",
            "art and culture          8752\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MmKEn5NTZEeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "img_height = 128\n",
        "img_width = 128"
      ],
      "metadata": {
        "id": "cIzLIoOEZE-j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqWZ1y3yh4ua",
        "outputId": "f1aedea6-6870-4755-8b52-e0faa644ecec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 35105 files belonging to 4 classes.\n",
            "Using 28084 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(  #the tf terminology for this method demands the term validation where we we might otherwise use the term test. Just know that validation in this case means test, we're not doing a 3-way split of the data nor k-fold cross-validation\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu-K3oJos8Hw",
        "outputId": "fd41fa93-0f6f-4fa9-afe8-62772e3006b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 35105 files belonging to 4 classes.\n",
            "Using 7021 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names_train = train_ds.class_names\n",
        "print(class_names_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB3EJiyktIs_",
        "outputId": "332cce33-14c0-4b22-c53b-61581ae5d29d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['architecure', 'art and culture', 'food and d rinks', 'travel and  adventure']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names_test = val_ds.class_names\n",
        "print(class_names_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjJG0G9HtJpW",
        "outputId": "0b348ada-878c-483e-d2f9-761ef5b38070"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['architecure', 'art and culture', 'food and d rinks', 'travel and  adventure']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(4)])"
      ],
      "metadata": {
        "id": "9N5RGnZrtZtm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "model.compile(optimizer='adam',loss=SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD894FTvt3c2",
        "outputId": "2db4bff9-3558-4266-a7bc-306b3b7583d9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1756/1756 [==============================] - 4404s 2s/step - loss: 1.4107 - accuracy: 0.2486 - val_loss: 1.3863 - val_accuracy: 0.2532\n",
            "Epoch 2/10\n",
            "1756/1756 [==============================] - 709s 404ms/step - loss: 1.3863 - accuracy: 0.2487 - val_loss: 1.3863 - val_accuracy: 0.2532\n",
            "Epoch 3/10\n",
            "1756/1756 [==============================] - 685s 390ms/step - loss: 1.3863 - accuracy: 0.2487 - val_loss: 1.3863 - val_accuracy: 0.2532\n",
            "Epoch 4/10\n",
            "1756/1756 [==============================] - 688s 391ms/step - loss: 1.3863 - accuracy: 0.2487 - val_loss: 1.3863 - val_accuracy: 0.2532\n",
            "Epoch 5/10\n",
            "1756/1756 [==============================] - 688s 391ms/step - loss: 1.3863 - accuracy: 0.2487 - val_loss: 1.3863 - val_accuracy: 0.2532\n",
            "Epoch 6/10\n",
            "1756/1756 [==============================] - 673s 383ms/step - loss: 1.3863 - accuracy: 0.2487 - val_loss: 1.3863 - val_accuracy: 0.2532\n",
            "Epoch 7/10\n",
            "1756/1756 [==============================] - 691s 393ms/step - loss: 1.3863 - accuracy: 0.2487 - val_loss: 1.3863 - val_accuracy: 0.2532\n",
            "Epoch 8/10\n",
            "1756/1756 [==============================] - 694s 395ms/step - loss: 1.3863 - accuracy: 0.2487 - val_loss: 1.3863 - val_accuracy: 0.2532\n",
            "Epoch 9/10\n",
            "1756/1756 [==============================] - 689s 392ms/step - loss: 1.3863 - accuracy: 0.2487 - val_loss: 1.3863 - val_accuracy: 0.2532\n",
            "Epoch 10/10\n",
            "1756/1756 [==============================] - 695s 395ms/step - loss: 1.3863 - accuracy: 0.2487 - val_loss: 1.3863 - val_accuracy: 0.2532\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7963e57d9bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "for images, labels in val_ds:\n",
        "    batch_predictions = model.predict(images)\n",
        "    batch_predicted_labels = np.argmax(batch_predictions, axis=1)\n",
        "    true_labels.extend(labels.numpy())\n",
        "    predicted_labels.extend(batch_predicted_labels)\n",
        "print(\"Classification Report:\\n\", classification_report(true_labels, predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRJfahzHvqz0",
        "outputId": "44fa67d5-5431-4f8e-9353-5dd11f64cc9d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "439/439 [==============================] - 72s 162ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      1.00      0.40      1778\n",
            "           1       0.00      0.00      0.00      1793\n",
            "           2       0.00      0.00      0.00      1703\n",
            "           3       0.00      0.00      0.00      1747\n",
            "\n",
            "    accuracy                           0.25      7021\n",
            "   macro avg       0.06      0.25      0.10      7021\n",
            "weighted avg       0.06      0.25      0.10      7021\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_shJMhFmyaRG",
        "outputId": "e270d90e-e382-47c9-f130-73d6f6ba2fb3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling (Rescaling)       (None, 128, 128, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 128, 128, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 64, 64, 16)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 32, 32, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 16, 16, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               2097280   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2121380 (8.09 MB)\n",
            "Trainable params: 2121380 (8.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}